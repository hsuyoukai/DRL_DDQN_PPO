import itertools
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
from algorithms.ppo.PPO import PPO
import plot
import torch.multiprocessing as mp
import os
from pathlib import Path

def main():
    plot.initialize()
    mp.set_start_method('spawn')
    np.set_printoptions(suppress=True)
    all_logs=[]


    for i in range(10):
        print(f"---------- round {i} ----------")
        plot_path = Path(f'plots/ppo/{i}2_testing.png')

        # ä¿éšªçµ²#1ï¼šå°±ç®—åœ–æª”å·²å­˜åœ¨ï¼Œä¹Ÿè‡³å°‘è·‘ä¸€æ¬¡ test() ä»¥ç¢ºä¿ç”¢ç”Ÿæ—¥èªŒ
        
        ppo = PPO(state_type='indicators', djia_year=2019, repeat=i)
        if not plot_path.is_file():
            ppo.train()
        ppo.test()  # ä¸€å®šæœƒè·‘

        print(f"ğŸ“Š ppo.env.history_log ç­†æ•¸ï¼š{len(ppo.env.history_log)}")
        all_logs.extend(ppo.env.history_log)

   
    if not all_logs:
        raise RuntimeError("history_log ç‚ºç©ºï¼šè«‹ç¢ºèª train()/test() æ˜¯å¦æœ‰åŸ·è¡ŒæˆåŠŸã€‚")

    # ç”¨ json_normalize å±•é–‹ dictï¼Œæ¯” pd.DataFrame(list) ç©©å®š
    df = pd.json_normalize(all_logs)
    print("df columns:", list(df.columns))

    needed = {"returns", "weights"}
    missing = needed - set(df.columns)
    if missing:
        sample_keys = list(all_logs[0].keys()) if isinstance(all_logs[0], dict) else "é dict"
        raise KeyError(f"ç¼ºå°‘æ¬„ä½: {missing}ï¼›è«‹ç¢ºèª env.history_log çš„éµåã€‚æ¨£æœ¬éµï¼š{sample_keys}")

    # æª¢æŸ¥ returns / weights æ˜¯å¦ç‚ºé•·åº¦=3 çš„åºåˆ—ï¼Œä¸¦å®‰å…¨å±•é–‹
    def _explode_vec_col(series, prefix):
        ok = series.map(lambda x: hasattr(x, "__len__") and len(x) == 3)
        if not ok.all():
            bad_idx = ok[~ok].index[:5].tolist()
            raise ValueError(f"{prefix} æ¬„ä½å‡ºç¾éé•·åº¦3çš„å€¼ï¼›å•é¡Œç´¢å¼•ï¼š{bad_idx}")
        return pd.DataFrame(series.tolist(), columns=[f"DBC_{prefix}", f"SHY_{prefix}", f"SPY_{prefix}"])

    returns_df = _explode_vec_col(df["returns"], "ret")
    weights_df = _explode_vec_col(df["weights"], "weight")

    # åˆä½µè¼¸å‡º
    df = df.drop(columns=["returns", "weights"]).reset_index(drop=True)
    out = pd.concat([df, returns_df, weights_df], axis=1)
    
    os.makedirs("output", exist_ok=True)
    out.to_csv("output/ppo_rounds_history.csv", index=False)
    print("æ‰€æœ‰ç´€éŒ„å·²å„²å­˜ç‚º output/ppo_rounds_history.csv")

if __name__ == '__main__':
    main()